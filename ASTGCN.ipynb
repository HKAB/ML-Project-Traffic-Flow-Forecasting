{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASTGCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HKAB/ML-Project-Traffic-Flow-Forecasting/blob/main/ASTGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VRYMhn-7vPf",
        "outputId": "84e8b05d-fa02-44c1-8ecd-f953d916df82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/traffic_data"
      ],
      "metadata": {
        "id": "OArkv8cW8YBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d750df-e3e3-4794-86a6-9fd27dd46374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1KuB5yZOxUbBW-9aYL0DYL8DGOVL_Ry1c/traffic_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "xBwOvsxp9zR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae20845-2f0d-4107-c733-32b50371d331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def re_normalization(x, mean, std):\n",
        "    x = x * std + mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def max_min_normalization(x, _max, _min):\n",
        "    x = 1. * (x - _min)/(_max - _min)\n",
        "    x = x * 2. - 1.\n",
        "    return x\n",
        "\n",
        "\n",
        "def re_max_min_normalization(x, _max, _min):\n",
        "    x = (x + 1.) / 2.\n",
        "    x = 1. * x * (_max - _min) + _min\n",
        "    return x\n",
        "    \n",
        "\n",
        "def search_data(sequence_length, num_of_depend, label_start_idx,\n",
        "                num_for_predict, units, points_per_hour):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequence_length: int, length of all history data\n",
        "    num_of_depend: int,\n",
        "    label_start_idx: int, the first index of predicting target\n",
        "    num_for_predict: int, the number of points will be predicted for each sample\n",
        "    units: int, week: 7 * 24, day: 24, recent(hour): 1\n",
        "    points_per_hour: int, number of points per hour, depends on data\n",
        "    Returns\n",
        "    ----------\n",
        "    list[(start_idx, end_idx)]\n",
        "    '''\n",
        "\n",
        "    if points_per_hour < 0:\n",
        "        raise ValueError(\"points_per_hour should be greater than 0!\")\n",
        "\n",
        "    if label_start_idx + num_for_predict > sequence_length:\n",
        "        return None\n",
        "\n",
        "    x_idx = []\n",
        "    for i in range(1, num_of_depend + 1):\n",
        "        start_idx = label_start_idx - points_per_hour * units * i\n",
        "        end_idx = start_idx + num_for_predict\n",
        "        if start_idx >= 0:\n",
        "            x_idx.append((start_idx, end_idx))\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    if len(x_idx) != num_of_depend:\n",
        "        return None\n",
        "\n",
        "    return x_idx[::-1]\n",
        "\n",
        "\n",
        "def get_sample_indices(data_sequence, num_of_weeks, num_of_days, num_of_hours,\n",
        "                       label_start_idx, num_for_predict, points_per_hour=12):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_sequence: np.ndarray\n",
        "                   shape is (sequence_length, num_of_vertices, num_of_features)\n",
        "    num_of_weeks, num_of_days, num_of_hours: int\n",
        "    label_start_idx: int, the first index of predicting target, 预测值开始的那个点\n",
        "    num_for_predict: int,\n",
        "                     the number of points will be predicted for each sample\n",
        "    points_per_hour: int, default 12, number of points per hour\n",
        "    Returns\n",
        "    ----------\n",
        "    week_sample: np.ndarray\n",
        "                 shape is (num_of_weeks * points_per_hour,\n",
        "                           num_of_vertices, num_of_features)\n",
        "    day_sample: np.ndarray\n",
        "                 shape is (num_of_days * points_per_hour,\n",
        "                           num_of_vertices, num_of_features)\n",
        "    hour_sample: np.ndarray\n",
        "                 shape is (num_of_hours * points_per_hour,\n",
        "                           num_of_vertices, num_of_features)\n",
        "    target: np.ndarray\n",
        "            shape is (num_for_predict, num_of_vertices, num_of_features)\n",
        "    '''\n",
        "    week_sample, day_sample, hour_sample = None, None, None\n",
        "\n",
        "    if label_start_idx + num_for_predict > data_sequence.shape[0]:\n",
        "        return week_sample, day_sample, hour_sample, None\n",
        "\n",
        "    if num_of_weeks > 0:\n",
        "        week_indices = search_data(data_sequence.shape[0], num_of_weeks,\n",
        "                                   label_start_idx, num_for_predict,\n",
        "                                   7 * 24, points_per_hour)\n",
        "        if not week_indices:\n",
        "            return None, None, None, None\n",
        "\n",
        "        week_sample = np.concatenate([data_sequence[i: j]\n",
        "                                      for i, j in week_indices], axis=0)\n",
        "\n",
        "    if num_of_days > 0:\n",
        "        day_indices = search_data(data_sequence.shape[0], num_of_days,\n",
        "                                  label_start_idx, num_for_predict,\n",
        "                                  24, points_per_hour)\n",
        "        if not day_indices:\n",
        "            return None, None, None, None\n",
        "\n",
        "        day_sample = np.concatenate([data_sequence[i: j]\n",
        "                                     for i, j in day_indices], axis=0)\n",
        "\n",
        "    if num_of_hours > 0:\n",
        "        hour_indices = search_data(data_sequence.shape[0], num_of_hours,\n",
        "                                   label_start_idx, num_for_predict,\n",
        "                                   1, points_per_hour)\n",
        "        if not hour_indices:\n",
        "            return None, None, None, None\n",
        "\n",
        "        hour_sample = np.concatenate([data_sequence[i: j]\n",
        "                                      for i, j in hour_indices], axis=0)\n",
        "\n",
        "    target = data_sequence[label_start_idx: label_start_idx + num_for_predict]\n",
        "\n",
        "    return week_sample, day_sample, hour_sample, target\n",
        "\n",
        "\n",
        "def read_and_generate_dataset(graph_signal_matrix_filename,\n",
        "                                                     num_of_weeks, num_of_days,\n",
        "                                                     num_of_hours, num_for_predict,\n",
        "                                                     points_per_hour=12, save=False):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    graph_signal_matrix_filename: str, path of graph signal matrix file\n",
        "    num_of_weeks, num_of_days, num_of_hours: int\n",
        "    num_for_predict: int\n",
        "    points_per_hour: int, default 12, depends on data\n",
        "    Returns\n",
        "    ----------\n",
        "    feature: np.ndarray,\n",
        "             shape is (num_of_samples, num_of_depend * points_per_hour,\n",
        "                       num_of_vertices, num_of_features)\n",
        "    target: np.ndarray,\n",
        "            shape is (num_of_samples, num_of_vertices, num_for_predict)\n",
        "    '''\n",
        "    data_seq = np.load(graph_signal_matrix_filename)['data']  # (sequence_length, num_of_vertices, num_of_features)\n",
        "\n",
        "    all_samples = []\n",
        "    for idx in range(data_seq.shape[0]):\n",
        "        sample = get_sample_indices(data_seq, num_of_weeks, num_of_days,\n",
        "                                    num_of_hours, idx, num_for_predict,\n",
        "                                    points_per_hour)\n",
        "        if ((sample[0] is None) and (sample[1] is None) and (sample[2] is None)):\n",
        "            continue\n",
        "\n",
        "        week_sample, day_sample, hour_sample, target = sample\n",
        "\n",
        "        sample = []  # [(week_sample),(day_sample),(hour_sample),target,time_sample]\n",
        "\n",
        "        if num_of_weeks > 0:\n",
        "            week_sample = np.expand_dims(week_sample, axis=0).transpose((0, 2, 3, 1))  # (1,N,F,T)\n",
        "            sample.append(week_sample)\n",
        "\n",
        "        if num_of_days > 0:\n",
        "            day_sample = np.expand_dims(day_sample, axis=0).transpose((0, 2, 3, 1))  # (1,N,F,T)\n",
        "            sample.append(day_sample)\n",
        "\n",
        "        if num_of_hours > 0:\n",
        "            hour_sample = np.expand_dims(hour_sample, axis=0).transpose((0, 2, 3, 1))  # (1,N,F,T)\n",
        "            sample.append(hour_sample)\n",
        "\n",
        "        target = np.expand_dims(target, axis=0).transpose((0, 2, 3, 1))[:, :, 0, :]  # (1,N,T)\n",
        "        sample.append(target)\n",
        "\n",
        "        time_sample = np.expand_dims(np.array([idx]), axis=0)  # (1,1)\n",
        "        sample.append(time_sample)\n",
        "\n",
        "        all_samples.append(\n",
        "            sample)  # sampe：[(week_sample),(day_sample),(hour_sample),target,time_sample] = [(1,N,F,Tw),(1,N,F,Td),(1,N,F,Th),(1,N,Tpre),(1,1)]\n",
        "\n",
        "    split_line1 = int(len(all_samples) * 0.6)\n",
        "    split_line2 = int(len(all_samples) * 0.8)\n",
        "\n",
        "    training_set = [np.concatenate(i, axis=0)\n",
        "                    for i in zip(*all_samples[:split_line1])]  # [(B,N,F,Tw),(B,N,F,Td),(B,N,F,Th),(B,N,Tpre),(B,1)]\n",
        "    validation_set = [np.concatenate(i, axis=0)\n",
        "                      for i in zip(*all_samples[split_line1: split_line2])]\n",
        "    testing_set = [np.concatenate(i, axis=0)\n",
        "                   for i in zip(*all_samples[split_line2:])]\n",
        "\n",
        "    train_x = np.concatenate(training_set[:-2], axis=-1)  # (B,N,F,T')\n",
        "    val_x = np.concatenate(validation_set[:-2], axis=-1)\n",
        "    test_x = np.concatenate(testing_set[:-2], axis=-1)\n",
        "\n",
        "    train_target = training_set[-2]  # (B,N,T)\n",
        "    val_target = validation_set[-2]\n",
        "    test_target = testing_set[-2]\n",
        "\n",
        "    train_timestamp = training_set[-1]  # (B,1)\n",
        "    val_timestamp = validation_set[-1]\n",
        "    test_timestamp = testing_set[-1]\n",
        "\n",
        "    (stats, train_x_norm, val_x_norm, test_x_norm) = normalization(train_x, val_x, test_x)\n",
        "\n",
        "    all_data = {\n",
        "        'train': {\n",
        "            'x': train_x_norm,\n",
        "            'target': train_target,\n",
        "            'timestamp': train_timestamp,\n",
        "        },\n",
        "        'val': {\n",
        "            'x': val_x_norm,\n",
        "            'target': val_target,\n",
        "            'timestamp': val_timestamp,\n",
        "        },\n",
        "        'test': {\n",
        "            'x': test_x_norm,\n",
        "            'target': test_target,\n",
        "            'timestamp': test_timestamp,\n",
        "        },\n",
        "        'stats': {\n",
        "            '_mean': stats['_mean'],\n",
        "            '_std': stats['_std'],\n",
        "        }\n",
        "    }\n",
        "    print('train x:', all_data['train']['x'].shape)\n",
        "    print('train target:', all_data['train']['target'].shape)\n",
        "    print('train timestamp:', all_data['train']['timestamp'].shape)\n",
        "    print()\n",
        "    print('val x:', all_data['val']['x'].shape)\n",
        "    print('val target:', all_data['val']['target'].shape)\n",
        "    print('val timestamp:', all_data['val']['timestamp'].shape)\n",
        "    print()\n",
        "    print('test x:', all_data['test']['x'].shape)\n",
        "    print('test target:', all_data['test']['target'].shape)\n",
        "    print('test timestamp:', all_data['test']['timestamp'].shape)\n",
        "    print()\n",
        "    print('train data _mean :', stats['_mean'].shape, stats['_mean'])\n",
        "    print('train data _std :', stats['_std'].shape, stats['_std'])\n",
        "\n",
        "    if save:\n",
        "        file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n",
        "        dirpath = os.path.dirname(graph_signal_matrix_filename)\n",
        "        filename = os.path.join(dirpath, file + '_r' + str(num_of_hours) + '_d' + str(num_of_days) + '_w' + str(num_of_weeks)) + '_astcgn'\n",
        "        print('save file:', filename)\n",
        "        np.savez_compressed(filename,\n",
        "                            train_x=all_data['train']['x'], train_target=all_data['train']['target'],\n",
        "                            train_timestamp=all_data['train']['timestamp'],\n",
        "                            val_x=all_data['val']['x'], val_target=all_data['val']['target'],\n",
        "                            val_timestamp=all_data['val']['timestamp'],\n",
        "                            test_x=all_data['test']['x'], test_target=all_data['test']['target'],\n",
        "                            test_timestamp=all_data['test']['timestamp'],\n",
        "                            mean=all_data['stats']['_mean'], std=all_data['stats']['_std']\n",
        "                            )\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def normalization(train, val, test):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    train, val, test: np.ndarray (B,N,F,T)\n",
        "    Returns\n",
        "    ----------\n",
        "    stats: dict, two keys: mean and std\n",
        "    train_norm, val_norm, test_norm: np.ndarray,\n",
        "                                     shape is the same as original\n",
        "    '''\n",
        "\n",
        "    assert train.shape[1:] == val.shape[1:] and val.shape[1:] == test.shape[1:]  # ensure the num of nodes is the same\n",
        "    mean = train.mean(axis=(0,1,3), keepdims=True)\n",
        "    std = train.std(axis=(0,1,3), keepdims=True)\n",
        "    print('mean.shape:',mean.shape)\n",
        "    print('std.shape:',std.shape)\n",
        "\n",
        "    def normalize(x):\n",
        "        return (x - mean) / std\n",
        "\n",
        "    train_norm = normalize(train)\n",
        "    val_norm = normalize(val)\n",
        "    test_norm = normalize(test)\n",
        "\n",
        "    return {'_mean': mean, '_std': std}, train_norm, val_norm, test_norm"
      ],
      "metadata": {
        "id": "oa3blpzK-lie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from scipy.sparse.linalg import eigs\n",
        "\n",
        "def get_adjacency_matrix(distance_df_filename, num_of_vertices, id_filename=None):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    distance_df_filename: str, path of the csv file contains edges information\n",
        "    num_of_vertices: int, the number of vertices\n",
        "    Returns\n",
        "    ----------\n",
        "    A: np.ndarray, adjacency matrix\n",
        "    '''\n",
        "    if 'npy' in distance_df_filename:\n",
        "\n",
        "        adj_mx = np.load(distance_df_filename)\n",
        "\n",
        "        return adj_mx, None\n",
        "\n",
        "    else:\n",
        "\n",
        "        import csv\n",
        "\n",
        "        A = np.zeros((int(num_of_vertices), int(num_of_vertices)),\n",
        "                     dtype=np.float32)\n",
        "\n",
        "        distaneA = np.zeros((int(num_of_vertices), int(num_of_vertices)),\n",
        "                            dtype=np.float32)\n",
        "\n",
        "        if id_filename:\n",
        "\n",
        "            with open(id_filename, 'r') as f:\n",
        "                id_dict = {int(i): idx for idx, i in enumerate(f.read().strip().split('\\n'))} \n",
        "\n",
        "            with open(distance_df_filename, 'r') as f:\n",
        "                f.readline()\n",
        "                reader = csv.reader(f)\n",
        "                for row in reader:\n",
        "                    if len(row) != 3:\n",
        "                        continue\n",
        "                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
        "                    A[id_dict[i], id_dict[j]] = 1\n",
        "                    distaneA[id_dict[i], id_dict[j]] = distance\n",
        "            return A, distaneA\n",
        "\n",
        "        else:\n",
        "\n",
        "            with open(distance_df_filename, 'r') as f:\n",
        "                f.readline()\n",
        "                reader = csv.reader(f)\n",
        "                for row in reader:\n",
        "                    if len(row) != 3:\n",
        "                        continue\n",
        "                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
        "                    A[i, j] = 1\n",
        "                    distaneA[i, j] = distance\n",
        "            return A, distaneA\n",
        "\n",
        "\n",
        "def scaled_Laplacian(W):\n",
        "    '''\n",
        "    compute \\tilde{L}\n",
        "    Parameters\n",
        "    ----------\n",
        "    W: np.ndarray, shape is (N, N), N is the num of vertices\n",
        "    Returns\n",
        "    ----------\n",
        "    scaled_Laplacian: np.ndarray, shape (N, N)\n",
        "    '''\n",
        "\n",
        "    assert W.shape[0] == W.shape[1]\n",
        "\n",
        "    D = np.diag(np.sum(W, axis=1))\n",
        "\n",
        "    L = D - W\n",
        "\n",
        "    lambda_max = eigs(L, k=1, which='LR')[0].real\n",
        "\n",
        "    return (2 * L) / lambda_max - np.identity(W.shape[0])\n",
        "\n",
        "\n",
        "def cheb_polynomial(L_tilde, K):\n",
        "    '''\n",
        "    compute a list of chebyshev polynomials from T_0 to T_{K-1}\n",
        "    Parameters\n",
        "    ----------\n",
        "    L_tilde: scaled Laplacian, np.ndarray, shape (N, N)\n",
        "    K: the maximum order of chebyshev polynomials\n",
        "    Returns\n",
        "    ----------\n",
        "    cheb_polynomials: list(np.ndarray), length: K, from T_0 to T_{K-1}\n",
        "    '''\n",
        "\n",
        "    N = L_tilde.shape[0]\n",
        "\n",
        "    cheb_polynomials = [np.identity(N), L_tilde.copy()]\n",
        "\n",
        "    for i in range(2, K):\n",
        "        cheb_polynomials.append(2 * L_tilde * cheb_polynomials[i - 1] - cheb_polynomials[i - 2])\n",
        "\n",
        "    return cheb_polynomials\n",
        "\n",
        "\n",
        "def load_graphdata_channel1(graph_signal_matrix_filename, num_of_hours, num_of_days, num_of_weeks, DEVICE, batch_size, shuffle=True):\n",
        "    '''\n",
        "    :param graph_signal_matrix_filename: str\n",
        "    :param num_of_hours: int\n",
        "    :param num_of_days: int\n",
        "    :param num_of_weeks: int\n",
        "    :param DEVICE:\n",
        "    :param batch_size: int\n",
        "    :return:\n",
        "    three DataLoaders, each dataloader contains:\n",
        "    test_x_tensor: (B, N_nodes, in_feature, T_input)\n",
        "    test_decoder_input_tensor: (B, N_nodes, T_output)\n",
        "    test_target_tensor: (B, N_nodes, T_output)\n",
        "    '''\n",
        "\n",
        "    file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n",
        "\n",
        "    dirpath = os.path.dirname(graph_signal_matrix_filename)\n",
        "\n",
        "    filename = os.path.join(dirpath,\n",
        "                            file + '_r' + str(num_of_hours) + '_d' + str(num_of_days) + '_w' + str(num_of_weeks)) +'_astcgn'\n",
        "\n",
        "    print('load file:', filename)\n",
        "\n",
        "    file_data = np.load(filename + '.npz')\n",
        "    train_x = file_data['train_x']  # (10181, 307, 3, 12)\n",
        "    train_x = train_x[:, :, 0:1, :]\n",
        "    train_target = file_data['train_target']  # (10181, 307, 12)\n",
        "\n",
        "    val_x = file_data['val_x']\n",
        "    val_x = val_x[:, :, 0:1, :]\n",
        "    val_target = file_data['val_target']\n",
        "\n",
        "    test_x = file_data['test_x']\n",
        "    test_x = test_x[:, :, 0:1, :]\n",
        "    test_target = file_data['test_target']\n",
        "\n",
        "    mean = file_data['mean'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
        "    std = file_data['std'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
        "\n",
        "    # ------- train_loader -------\n",
        "    train_x_tensor = torch.from_numpy(train_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "    train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    # ------- val_loader -------\n",
        "    val_x_tensor = torch.from_numpy(val_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "    val_target_tensor = torch.from_numpy(val_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "\n",
        "    val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # ------- test_loader -------\n",
        "    test_x_tensor = torch.from_numpy(test_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "    test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "\n",
        "    test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # print\n",
        "    print('train:', train_x_tensor.size(), train_target_tensor.size())\n",
        "    print('val:', val_x_tensor.size(), val_target_tensor.size())\n",
        "    print('test:', test_x_tensor.size(), test_target_tensor.size())\n",
        "\n",
        "    return train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std\n",
        "\n",
        "\n",
        "def compute_val_loss_mstgcn(net, val_loader, criterion, sw, epoch, limit=None):\n",
        "    '''\n",
        "    for rnn, compute mean loss on validation set\n",
        "    :param net: model\n",
        "    :param val_loader: torch.utils.data.utils.DataLoader\n",
        "    :param criterion: torch.nn.MSELoss\n",
        "    :param sw: tensorboardX.SummaryWriter\n",
        "    :param global_step: int, current global_step\n",
        "    :param limit: int,\n",
        "    :return: val_loss\n",
        "    '''\n",
        "\n",
        "    net.train(False)  # ensure dropout layers are in evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        val_loader_length = len(val_loader)  # nb of batch\n",
        "\n",
        "        tmp = []  \n",
        "\n",
        "        for batch_index, batch_data in enumerate(val_loader):\n",
        "            encoder_inputs, labels = batch_data\n",
        "            outputs = net(encoder_inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            tmp.append(loss.item())\n",
        "            if batch_index % 100 == 0:\n",
        "                print('validation batch %s / %s, loss: %.2f' % (batch_index + 1, val_loader_length, loss.item()))\n",
        "            if (limit is not None) and batch_index >= limit:\n",
        "                break\n",
        "\n",
        "        validation_loss = sum(tmp) / len(tmp)\n",
        "        sw.add_scalar('validation_loss', validation_loss, epoch)\n",
        "    return validation_loss\n",
        "\n",
        "\n",
        "def evaluate_on_test_mstgcn(net, test_loader, test_target_tensor, sw, epoch, _mean, _std):\n",
        "    '''\n",
        "    for rnn, compute MAE, RMSE, MAPE scores of the prediction for every time step on testing set.\n",
        "\n",
        "    :param net: model\n",
        "    :param test_loader: torch.utils.data.utils.DataLoader\n",
        "    :param test_target_tensor: torch.tensor (B, N_nodes, T_output, out_feature)=(B, N_nodes, T_output, 1)\n",
        "    :param sw:\n",
        "    :param epoch: int, current epoch\n",
        "    :param _mean: (1, 1, 3(features), 1)\n",
        "    :param _std: (1, 1, 3(features), 1)\n",
        "    '''\n",
        "\n",
        "    net.train(False)  # ensure dropout layers are in test mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        test_loader_length = len(test_loader)\n",
        "\n",
        "        test_target_tensor = test_target_tensor.cpu().numpy()\n",
        "\n",
        "        prediction = []  \n",
        "\n",
        "        for batch_index, batch_data in enumerate(test_loader):\n",
        "\n",
        "            encoder_inputs, labels = batch_data\n",
        "\n",
        "            outputs = net(encoder_inputs)\n",
        "\n",
        "            prediction.append(outputs.detach().cpu().numpy())\n",
        "\n",
        "            if batch_index % 100 == 0:\n",
        "                print('predicting testing set batch %s / %s' % (batch_index + 1, test_loader_length))\n",
        "\n",
        "        prediction = np.concatenate(prediction, 0)  # (batch, T', 1)\n",
        "        prediction_length = prediction.shape[2]\n",
        "\n",
        "        for i in range(prediction_length):\n",
        "            assert test_target_tensor.shape[0] == prediction.shape[0]\n",
        "            print('current epoch: %s, predict %s points' % (epoch, i))\n",
        "            mae = mean_absolute_error(test_target_tensor[:, :, i], prediction[:, :, i])\n",
        "            rmse = mean_squared_error(test_target_tensor[:, :, i], prediction[:, :, i]) ** 0.5\n",
        "            mape = mean_absolute_percentage_error(test_target_tensor[:, :, i], prediction[:, :, i])\n",
        "            print('MAE: %.2f' % (mae))\n",
        "            print('RMSE: %.2f' % (rmse))\n",
        "            print('MAPE: %.2f' % (mape))\n",
        "            print()\n",
        "            if sw:\n",
        "                sw.add_scalar('MAE_%s_points' % (i), mae, epoch)\n",
        "                sw.add_scalar('RMSE_%s_points' % (i), rmse, epoch)\n",
        "                sw.add_scalar('MAPE_%s_points' % (i), mape, epoch)\n",
        "\n",
        "\n",
        "def predict_and_save_results_mstgcn(net, data_loader, data_target_tensor, global_step,_mean, _std, params_path, type):\n",
        "    '''\n",
        "    :param net: nn.Module\n",
        "    :param data_loader: torch.utils.data.utils.DataLoader\n",
        "    :param data_target_tensor: tensor\n",
        "    :param epoch: int\n",
        "    :param _mean: (1, 1, 3, 1)\n",
        "    :param _std: (1, 1, 3, 1)\n",
        "    :param params_path: the path for saving the results\n",
        "    :return:\n",
        "    '''\n",
        "    net.train(False)  # ensure dropout layers are in test mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        data_target_tensor = data_target_tensor.cpu().numpy()\n",
        "\n",
        "        loader_length = len(data_loader)  # nb of batch\n",
        "\n",
        "        prediction = []  \n",
        "\n",
        "        input = []  \n",
        "        for batch_index, batch_data in enumerate(data_loader):\n",
        "\n",
        "            encoder_inputs, labels = batch_data\n",
        "\n",
        "            input.append(encoder_inputs[:, :, 0:1].cpu().numpy())  # (batch, T', 1)\n",
        "\n",
        "            outputs = net(encoder_inputs)\n",
        "\n",
        "            prediction.append(outputs.detach().cpu().numpy())\n",
        "\n",
        "            if batch_index % 100 == 0:\n",
        "                print('predicting data set batch %s / %s' % (batch_index + 1, loader_length))\n",
        "\n",
        "        input = np.concatenate(input, 0)\n",
        "\n",
        "        input = re_normalization(input, _mean, _std)\n",
        "\n",
        "        prediction = np.concatenate(prediction, 0)  # (batch, T', 1)\n",
        "\n",
        "        print('input:', input.shape)\n",
        "        print('prediction:', prediction.shape)\n",
        "        print('data_target_tensor:', data_target_tensor.shape)\n",
        "        output_filename = os.path.join(params_path, 'output_epoch_%s_%s' % (global_step, type))\n",
        "        np.savez(output_filename, input=input, prediction=prediction, data_target_tensor=data_target_tensor)\n",
        "\n",
        "        excel_list = []\n",
        "        prediction_length = prediction.shape[2]\n",
        "\n",
        "        for i in range(prediction_length):\n",
        "            assert data_target_tensor.shape[0] == prediction.shape[0]\n",
        "            print('current epoch: %s, predict %s points' % (global_step, i))\n",
        "            \n",
        "            mae = mean_absolute_error(data_target_tensor[:, :, i], prediction[:, :, i])\n",
        "            rmse = mean_squared_error(data_target_tensor[:, :, i], prediction[:, :, i]) ** 0.5\n",
        "            mape = mean_absolute_percentage_error(data_target_tensor[:, :, i], prediction[:, :, i])\n",
        "\n",
        "            print('MAE: %.2f' % (mae))\n",
        "            print('RMSE: %.2f' % (rmse))\n",
        "            print('MAPE: %.2f' % (mape))\n",
        "            excel_list.extend([mae, rmse, mape])\n",
        "\n",
        "        # print overall results\n",
        "        \n",
        "        mae = mean_absolute_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1))\n",
        "        rmse = mean_squared_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1)) ** 0.5\n",
        "        mape = mean_absolute_percentage_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1))\n",
        "        print('all MAE: %.2f' % (mae))\n",
        "        print('all RMSE: %.2f' % (rmse))\n",
        "        print('all MAPE: %.2f' % (mape))\n",
        "        excel_list.extend([mae, rmse, mape])\n",
        "        print(excel_list)"
      ],
      "metadata": {
        "id": "c9fCk9cuNyZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Spatial_Attention_layer(nn.Module):\n",
        "    '''\n",
        "    compute spatial attention scores\n",
        "    '''\n",
        "    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n",
        "        super(Spatial_Attention_layer, self).__init__()\n",
        "        self.W1 = nn.Parameter(torch.FloatTensor(num_of_timesteps).to(DEVICE))\n",
        "        self.W2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_timesteps).to(DEVICE))\n",
        "        self.W3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n",
        "        self.bs = nn.Parameter(torch.FloatTensor(1, num_of_vertices, num_of_vertices).to(DEVICE))\n",
        "        self.Vs = nn.Parameter(torch.FloatTensor(num_of_vertices, num_of_vertices).to(DEVICE))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (B,N,N)\n",
        "        '''\n",
        "\n",
        "        lhs = torch.matmul(torch.matmul(x, self.W1), self.W2)  # (b,N,F,T)(T)->(b,N,F)(F,T)->(b,N,T)\n",
        "\n",
        "        rhs = torch.matmul(self.W3, x).transpose(-1, -2)  # (F)(b,N,F,T)->(b,N,T)->(b,T,N)\n",
        "\n",
        "        product = torch.matmul(lhs, rhs)  # (b,N,T)(b,T,N) -> (B, N, N)\n",
        "\n",
        "        S = torch.matmul(self.Vs, torch.sigmoid(product + self.bs))  # (N,N)(B, N, N)->(B,N,N)\n",
        "\n",
        "        S_normalized = F.softmax(S, dim=1)\n",
        "\n",
        "        return S_normalized\n",
        "\n",
        "\n",
        "class cheb_conv_withSAt(nn.Module):\n",
        "    '''\n",
        "    K-order chebyshev graph convolution\n",
        "    '''\n",
        "\n",
        "    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n",
        "        '''\n",
        "        :param K: int\n",
        "        :param in_channles: int, num of channels in the input sequence\n",
        "        :param out_channels: int, num of channels in the output sequence\n",
        "        '''\n",
        "        super(cheb_conv_withSAt, self).__init__()\n",
        "        self.K = K\n",
        "        self.cheb_polynomials = cheb_polynomials\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.DEVICE = cheb_polynomials[0].device\n",
        "        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n",
        "\n",
        "    def forward(self, x, spatial_attention):\n",
        "        '''\n",
        "        Chebyshev graph convolution operation\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (batch_size, N, F_out, T)\n",
        "        '''\n",
        "\n",
        "        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for time_step in range(num_of_timesteps):\n",
        "\n",
        "            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n",
        "\n",
        "            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n",
        "\n",
        "            for k in range(self.K):\n",
        "\n",
        "                T_k = self.cheb_polynomials[k]  # (N,N)\n",
        "\n",
        "                T_k_with_at = T_k.mul(spatial_attention)   # (N,N)*(N,N) = (N,N) \n",
        "\n",
        "                theta_k = self.Theta[k]  # (in_channel, out_channel)\n",
        "\n",
        "                rhs = T_k_with_at.permute(0, 2, 1).matmul(graph_signal)  # (N, N)(b, N, F_in) = (b, N, F_in)\n",
        "\n",
        "                output = output + rhs.matmul(theta_k)  # (b, N, F_in)(F_in, F_out) = (b, N, F_out)\n",
        "\n",
        "            outputs.append(output.unsqueeze(-1))  # (b, N, F_out, 1)\n",
        "\n",
        "        return F.relu(torch.cat(outputs, dim=-1))  # (b, N, F_out, T)\n",
        "\n",
        "\n",
        "class Temporal_Attention_layer(nn.Module):\n",
        "    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n",
        "        super(Temporal_Attention_layer, self).__init__()\n",
        "        self.U1 = nn.Parameter(torch.FloatTensor(num_of_vertices).to(DEVICE))\n",
        "        self.U2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_vertices).to(DEVICE))\n",
        "        self.U3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n",
        "        self.be = nn.Parameter(torch.FloatTensor(1, num_of_timesteps, num_of_timesteps).to(DEVICE))\n",
        "        self.Ve = nn.Parameter(torch.FloatTensor(num_of_timesteps, num_of_timesteps).to(DEVICE))\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (B, T, T)\n",
        "        '''\n",
        "        _, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n",
        "\n",
        "        lhs = torch.matmul(torch.matmul(x.permute(0, 3, 2, 1), self.U1), self.U2)\n",
        "        # x:(B, N, F_in, T) -> (B, T, F_in, N)\n",
        "        # (B, T, F_in, N)(N) -> (B,T,F_in)\n",
        "        # (B,T,F_in)(F_in,N)->(B,T,N)\n",
        "\n",
        "        rhs = torch.matmul(self.U3, x)  # (F)(B,N,F,T)->(B, N, T)\n",
        "\n",
        "        product = torch.matmul(lhs, rhs)  # (B,T,N)(B,N,T)->(B,T,T)\n",
        "\n",
        "        E = torch.matmul(self.Ve, torch.sigmoid(product + self.be))  # (B, T, T)\n",
        "\n",
        "        E_normalized = F.softmax(E, dim=1)\n",
        "\n",
        "        return E_normalized\n",
        "\n",
        "\n",
        "class cheb_conv(nn.Module):\n",
        "    '''\n",
        "    K-order chebyshev graph convolution\n",
        "    '''\n",
        "\n",
        "    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n",
        "        '''\n",
        "        :param K: int\n",
        "        :param in_channles: int, num of channels in the input sequence\n",
        "        :param out_channels: int, num of channels in the output sequence\n",
        "        '''\n",
        "        super(cheb_conv, self).__init__()\n",
        "        self.K = K\n",
        "        self.cheb_polynomials = cheb_polynomials\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.DEVICE = cheb_polynomials[0].device\n",
        "        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Chebyshev graph convolution operation\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (batch_size, N, F_out, T)\n",
        "        '''\n",
        "\n",
        "        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for time_step in range(num_of_timesteps):\n",
        "\n",
        "            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n",
        "\n",
        "            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n",
        "\n",
        "            for k in range(self.K):\n",
        "\n",
        "                T_k = self.cheb_polynomials[k]  # (N,N)\n",
        "\n",
        "                theta_k = self.Theta[k]  # (in_channel, out_channel)\n",
        "\n",
        "                rhs = graph_signal.permute(0, 2, 1).matmul(T_k).permute(0, 2, 1)\n",
        "\n",
        "                output = output + rhs.matmul(theta_k)\n",
        "\n",
        "            outputs.append(output.unsqueeze(-1))\n",
        "\n",
        "        return F.relu(torch.cat(outputs, dim=-1))\n",
        "\n",
        "\n",
        "class ASTGCN_block(nn.Module):\n",
        "\n",
        "    def __init__(self, DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, num_of_timesteps):\n",
        "        super(ASTGCN_block, self).__init__()\n",
        "        self.TAt = Temporal_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n",
        "        self.SAt = Spatial_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n",
        "        self.cheb_conv_SAt = cheb_conv_withSAt(K, cheb_polynomials, in_channels, nb_chev_filter)\n",
        "        self.time_conv = nn.Conv2d(nb_chev_filter, nb_time_filter, kernel_size=(1, 3), stride=(1, time_strides), padding=(0, 1))\n",
        "        self.residual_conv = nn.Conv2d(in_channels, nb_time_filter, kernel_size=(1, 1), stride=(1, time_strides))\n",
        "        self.ln = nn.LayerNorm(nb_time_filter) \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (batch_size, N, nb_time_filter, T)\n",
        "        '''\n",
        "        batch_size, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n",
        "\n",
        "        # TAt\n",
        "        temporal_At = self.TAt(x)  # (b, T, T)\n",
        "\n",
        "        x_TAt = torch.matmul(x.reshape(batch_size, -1, num_of_timesteps), temporal_At).reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n",
        "\n",
        "        # SAt\n",
        "        spatial_At = self.SAt(x_TAt)\n",
        "\n",
        "        # cheb gcn\n",
        "        spatial_gcn = self.cheb_conv_SAt(x, spatial_At)  # (b,N,F,T)\n",
        "        # spatial_gcn = self.cheb_conv(x)\n",
        "\n",
        "        # convolution along the time axis\n",
        "        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) \n",
        "\n",
        "        # residual shortcut\n",
        "        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) 用(1,1)\n",
        "\n",
        "        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)\n",
        "        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n",
        "\n",
        "        return x_residual\n",
        "\n",
        "\n",
        "class ASTGCN_submodule(nn.Module):\n",
        "\n",
        "    def __init__(self, DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices):\n",
        "        '''\n",
        "        :param nb_block:\n",
        "        :param in_channels:\n",
        "        :param K:\n",
        "        :param nb_chev_filter:\n",
        "        :param nb_time_filter:\n",
        "        :param time_strides:\n",
        "        :param cheb_polynomials:\n",
        "        :param nb_predict_step:\n",
        "        '''\n",
        "\n",
        "        super(ASTGCN_submodule, self).__init__()\n",
        "\n",
        "        self.BlockList = nn.ModuleList([ASTGCN_block(DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, len_input)])\n",
        "\n",
        "        self.BlockList.extend([ASTGCN_block(DEVICE, nb_time_filter, K, nb_chev_filter, nb_time_filter, 1, cheb_polynomials, num_of_vertices, len_input//time_strides) for _ in range(nb_block-1)])\n",
        "\n",
        "        self.final_conv = nn.Conv2d(int(len_input/time_strides), num_for_predict, kernel_size=(1, nb_time_filter))\n",
        "\n",
        "        self.DEVICE = DEVICE\n",
        "\n",
        "        self.to(DEVICE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (B, N_nodes, F_in, T_in)\n",
        "        :return: (B, N_nodes, T_out)\n",
        "        '''\n",
        "        for block in self.BlockList:\n",
        "            x = block(x)\n",
        "\n",
        "        output = self.final_conv(x.permute(0, 3, 1, 2))[:, :, :, -1].permute(0, 2, 1)\n",
        "        # (b,N,F,T)->(b,T,N,F)-conv<1,F>->(b,c_out*T,N,1)->(b,c_out*T,N)->(b,N,T)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, adj_mx, num_for_predict, len_input, num_of_vertices):\n",
        "    '''\n",
        "    :param DEVICE:\n",
        "    :param nb_block:\n",
        "    :param in_channels:\n",
        "    :param K:\n",
        "    :param nb_chev_filter:\n",
        "    :param nb_time_filter:\n",
        "    :param time_strides:\n",
        "    :param cheb_polynomials:\n",
        "    :param nb_predict_step:\n",
        "    :param len_input\n",
        "    :return:\n",
        "    '''\n",
        "    L_tilde = scaled_Laplacian(adj_mx)\n",
        "    cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n",
        "    model = ASTGCN_submodule(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices)\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "        else:\n",
        "            nn.init.uniform_(p)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "rOjOQ8vkM_5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "from time import time\n",
        "import shutil\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "num_of_vertices = 307\n",
        "points_per_hour = 12\n",
        "num_for_predict = 12\n",
        "len_input = 12\n",
        "dataset_name = 'pems04'\n",
        "\n",
        "model_name = 'ASTGCN'\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
        "print(\"CUDA:\", USE_CUDA, DEVICE)\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 80\n",
        "start_epoch = 0\n",
        "batch_size = 32\n",
        "num_of_weeks = 0\n",
        "num_of_days = 0\n",
        "num_of_hours = 1\n",
        "time_strides = num_of_hours\n",
        "nb_chev_filter = 64\n",
        "nb_time_filter = 64\n",
        "points_per_hour = 12\n",
        "in_channels = 1\n",
        "nb_block = 2\n",
        "K = 3\n",
        "loss_function = 'mse'\n",
        "\n",
        "folder_dir = '%s_h%dd%dw%d_channel%d_%e' % (model_name, num_of_hours, num_of_days, num_of_weeks, in_channels, learning_rate)\n",
        "print('folder_dir:', folder_dir)\n",
        "params_path = os.path.join('experiments', dataset_name, folder_dir)\n",
        "print('params_path:', params_path)\n",
        "\n",
        "graph_signal_matrix_filename = 'pems04.npz'\n",
        "id_filename = None\n",
        "adj_filename = 'distance.csv'\n",
        "\n",
        "# all_data = read_and_generate_dataset(graph_signal_matrix_filename, num_of_weeks, num_of_days, num_of_hours, \n",
        "#                                       num_for_predict, points_per_hour=points_per_hour, save=True)\n",
        "\n",
        "train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, _mean, _std = load_graphdata_channel1(\n",
        "    graph_signal_matrix_filename, num_of_hours,\n",
        "    num_of_days, num_of_weeks, DEVICE, batch_size)\n",
        "\n",
        "adj_mx, distance_mx = get_adjacency_matrix(adj_filename, num_of_vertices, id_filename)\n",
        "\n",
        "net = make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, adj_mx,\n",
        "                 num_for_predict, len_input, num_of_vertices)"
      ],
      "metadata": {
        "id": "V-Dn6G0LNTyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05737ffb-244d-4fee-f95e-e99a236efaa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: True cuda:0\n",
            "folder_dir: ASTGCN_h1d0w0_channel1_1.000000e-03\n",
            "params_path: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03\n",
            "load file: pems04_r1_d0_w0_astcgn\n",
            "train: torch.Size([10181, 307, 1, 12]) torch.Size([10181, 307, 12])\n",
            "val: torch.Size([3394, 307, 1, 12]) torch.Size([3394, 307, 12])\n",
            "test: torch.Size([3394, 307, 1, 12]) torch.Size([3394, 307, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main():\n",
        "    if (start_epoch == 0) and (not os.path.exists(params_path)):\n",
        "        os.makedirs(params_path)\n",
        "        print('create params directory %s' % (params_path))\n",
        "    elif (start_epoch == 0) and (os.path.exists(params_path)):\n",
        "        shutil.rmtree(params_path)\n",
        "        os.makedirs(params_path)\n",
        "        print('delete the old one and create params directory %s' % (params_path))\n",
        "    elif (start_epoch > 0) and (os.path.exists(params_path)):\n",
        "        print('train from params directory %s' % (params_path))\n",
        "    else:\n",
        "        raise SystemExit('Wrong type of model!')\n",
        "\n",
        "    print('param list:')\n",
        "    print('CUDA\\t', DEVICE)\n",
        "    print('in_channels\\t', in_channels)\n",
        "    print('nb_block\\t', nb_block)\n",
        "    print('nb_chev_filter\\t', nb_chev_filter)\n",
        "    print('nb_time_filter\\t', nb_time_filter)\n",
        "    print('time_strides\\t', time_strides)\n",
        "    print('batch_size\\t', batch_size)\n",
        "    print('graph_signal_matrix_filename\\t', graph_signal_matrix_filename)\n",
        "    print('start_epoch\\t', start_epoch)\n",
        "    print('epochs\\t', epochs)\n",
        "    criterion = nn.L1Loss().to(DEVICE)\n",
        "\n",
        "    if loss_function == 'mae':\n",
        "        criterion = nn.L1Loss().to(DEVICE)\n",
        "    elif loss_function == 'rmse':\n",
        "        criterion = nn.MSELoss().to(DEVICE)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    sw = SummaryWriter(logdir=params_path, flush_secs=5)\n",
        "    print(net)\n",
        "\n",
        "    print('Net\\'s state_dict:')\n",
        "    total_param = 0\n",
        "    for param_tensor in net.state_dict():\n",
        "        print(param_tensor, '\\t', net.state_dict()[param_tensor].size())\n",
        "        total_param += np.prod(net.state_dict()[param_tensor].size())\n",
        "    print('Net\\'s total params:', total_param)\n",
        "\n",
        "    print('Optimizer\\'s state_dict:')\n",
        "    for var_name in optimizer.state_dict():\n",
        "        print(var_name, '\\t', optimizer.state_dict()[var_name])\n",
        "\n",
        "    global_step = 0\n",
        "    best_epoch = 0\n",
        "    best_val_loss = np.inf\n",
        "\n",
        "    start_time = time()\n",
        "\n",
        "    if start_epoch > 0:\n",
        "\n",
        "        params_filename = os.path.join(params_path, 'epoch_%s.params' % start_epoch)\n",
        "\n",
        "        net.load_state_dict(torch.load(params_filename))\n",
        "\n",
        "        print('start epoch:', start_epoch)\n",
        "\n",
        "        print('load weight from: ', params_filename)\n",
        "\n",
        "    # train model\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "\n",
        "        params_filename = os.path.join(params_path, 'epoch_%s.params' % epoch)\n",
        "\n",
        "        \n",
        "        val_loss = compute_val_loss_mstgcn(net, val_loader, criterion, sw, epoch)\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "            torch.save(net.state_dict(), params_filename)\n",
        "            print('save parameters to file: %s' % params_filename)\n",
        "\n",
        "        net.train()  # ensure dropout layers are in train mode\n",
        "\n",
        "        for batch_index, batch_data in enumerate(train_loader):\n",
        "\n",
        "            encoder_inputs, labels = batch_data\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(encoder_inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss = loss.item()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            sw.add_scalar('training_loss', training_loss, global_step)\n",
        "\n",
        "            if global_step % 1000 == 0:\n",
        "\n",
        "                print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step, training_loss, time() - start_time))\n",
        "\n",
        "    print('best epoch:', best_epoch)\n",
        "\n",
        "    # apply the best model on the test set\n",
        "    predict_main(best_epoch, test_loader, test_target_tensor,_mean, _std, 'test')\n",
        "\n",
        "\n",
        "def predict_main(global_step, data_loader, data_target_tensor, _mean, _std, type):\n",
        "    '''\n",
        "    :param global_step: int\n",
        "    :param data_loader: torch.utils.data.utils.DataLoader\n",
        "    :param data_target_tensor: tensor\n",
        "    :param mean: (1, 1, 3, 1)\n",
        "    :param std: (1, 1, 3, 1)\n",
        "    :param type: string\n",
        "    :return:\n",
        "    '''\n",
        "\n",
        "    params_filename = os.path.join(params_path, 'epoch_%s.params' % global_step)\n",
        "    print('load weight from:', params_filename)\n",
        "\n",
        "    net.load_state_dict(torch.load(params_filename))\n",
        "\n",
        "    predict_and_save_results_mstgcn(net, data_loader, data_target_tensor, global_step,_mean, _std, params_path, type)"
      ],
      "metadata": {
        "id": "6URotIqmcdwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_main()"
      ],
      "metadata": {
        "id": "PtzM7UW3S2xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bb830e-9ce7-440c-a271-ebb5a15bdd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delete the old one and create params directory experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03\n",
            "param list:\n",
            "CUDA\t cuda:0\n",
            "in_channels\t 1\n",
            "nb_block\t 2\n",
            "nb_chev_filter\t 64\n",
            "nb_time_filter\t 64\n",
            "time_strides\t 1\n",
            "batch_size\t 32\n",
            "graph_signal_matrix_filename\t pems04.npz\n",
            "start_epoch\t 0\n",
            "epochs\t 80\n",
            "ASTGCN_submodule(\n",
            "  (BlockList): ModuleList(\n",
            "    (0): ASTGCN_block(\n",
            "      (TAt): Temporal_Attention_layer()\n",
            "      (SAt): Spatial_Attention_layer()\n",
            "      (cheb_conv_SAt): cheb_conv_withSAt(\n",
            "        (Theta): ParameterList(\n",
            "            (0): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]\n",
            "            (1): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]\n",
            "            (2): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]\n",
            "        )\n",
            "      )\n",
            "      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "      (residual_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): ASTGCN_block(\n",
            "      (TAt): Temporal_Attention_layer()\n",
            "      (SAt): Spatial_Attention_layer()\n",
            "      (cheb_conv_SAt): cheb_conv_withSAt(\n",
            "        (Theta): ParameterList(\n",
            "            (0): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]\n",
            "            (1): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]\n",
            "            (2): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]\n",
            "        )\n",
            "      )\n",
            "      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "      (residual_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (final_conv): Conv2d(12, 12, kernel_size=(1, 64), stride=(1, 1))\n",
            ")\n",
            "Net's state_dict:\n",
            "BlockList.0.TAt.U1 \t torch.Size([307])\n",
            "BlockList.0.TAt.U2 \t torch.Size([1, 307])\n",
            "BlockList.0.TAt.U3 \t torch.Size([1])\n",
            "BlockList.0.TAt.be \t torch.Size([1, 12, 12])\n",
            "BlockList.0.TAt.Ve \t torch.Size([12, 12])\n",
            "BlockList.0.SAt.W1 \t torch.Size([12])\n",
            "BlockList.0.SAt.W2 \t torch.Size([1, 12])\n",
            "BlockList.0.SAt.W3 \t torch.Size([1])\n",
            "BlockList.0.SAt.bs \t torch.Size([1, 307, 307])\n",
            "BlockList.0.SAt.Vs \t torch.Size([307, 307])\n",
            "BlockList.0.cheb_conv_SAt.Theta.0 \t torch.Size([1, 64])\n",
            "BlockList.0.cheb_conv_SAt.Theta.1 \t torch.Size([1, 64])\n",
            "BlockList.0.cheb_conv_SAt.Theta.2 \t torch.Size([1, 64])\n",
            "BlockList.0.time_conv.weight \t torch.Size([64, 64, 1, 3])\n",
            "BlockList.0.time_conv.bias \t torch.Size([64])\n",
            "BlockList.0.residual_conv.weight \t torch.Size([64, 1, 1, 1])\n",
            "BlockList.0.residual_conv.bias \t torch.Size([64])\n",
            "BlockList.0.ln.weight \t torch.Size([64])\n",
            "BlockList.0.ln.bias \t torch.Size([64])\n",
            "BlockList.1.TAt.U1 \t torch.Size([307])\n",
            "BlockList.1.TAt.U2 \t torch.Size([64, 307])\n",
            "BlockList.1.TAt.U3 \t torch.Size([64])\n",
            "BlockList.1.TAt.be \t torch.Size([1, 12, 12])\n",
            "BlockList.1.TAt.Ve \t torch.Size([12, 12])\n",
            "BlockList.1.SAt.W1 \t torch.Size([12])\n",
            "BlockList.1.SAt.W2 \t torch.Size([64, 12])\n",
            "BlockList.1.SAt.W3 \t torch.Size([64])\n",
            "BlockList.1.SAt.bs \t torch.Size([1, 307, 307])\n",
            "BlockList.1.SAt.Vs \t torch.Size([307, 307])\n",
            "BlockList.1.cheb_conv_SAt.Theta.0 \t torch.Size([64, 64])\n",
            "BlockList.1.cheb_conv_SAt.Theta.1 \t torch.Size([64, 64])\n",
            "BlockList.1.cheb_conv_SAt.Theta.2 \t torch.Size([64, 64])\n",
            "BlockList.1.time_conv.weight \t torch.Size([64, 64, 1, 3])\n",
            "BlockList.1.time_conv.bias \t torch.Size([64])\n",
            "BlockList.1.residual_conv.weight \t torch.Size([64, 64, 1, 1])\n",
            "BlockList.1.residual_conv.bias \t torch.Size([64])\n",
            "BlockList.1.ln.weight \t torch.Size([64])\n",
            "BlockList.1.ln.bias \t torch.Size([64])\n",
            "final_conv.weight \t torch.Size([12, 12, 1, 64])\n",
            "final_conv.bias \t torch.Size([12])\n",
            "Net's total params: 450031\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}]\n",
            "validation batch 1 / 107, loss: 275.10\n",
            "validation batch 101 / 107, loss: 331.26\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_0.params\n",
            "validation batch 1 / 107, loss: 59.21\n",
            "validation batch 101 / 107, loss: 89.33\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_1.params\n",
            "validation batch 1 / 107, loss: 35.41\n",
            "validation batch 101 / 107, loss: 42.87\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_2.params\n",
            "validation batch 1 / 107, loss: 29.77\n",
            "validation batch 101 / 107, loss: 36.66\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_3.params\n",
            "global step: 1000, training loss: 26.18, time: 205.55s\n",
            "validation batch 1 / 107, loss: 29.01\n",
            "validation batch 101 / 107, loss: 35.42\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_4.params\n",
            "validation batch 1 / 107, loss: 28.17\n",
            "validation batch 101 / 107, loss: 34.72\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_5.params\n",
            "validation batch 1 / 107, loss: 28.35\n",
            "validation batch 101 / 107, loss: 33.15\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_6.params\n",
            "global step: 2000, training loss: 21.14, time: 399.42s\n",
            "validation batch 1 / 107, loss: 27.58\n",
            "validation batch 101 / 107, loss: 32.58\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_7.params\n",
            "validation batch 1 / 107, loss: 26.86\n",
            "validation batch 101 / 107, loss: 32.55\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_8.params\n",
            "validation batch 1 / 107, loss: 26.82\n",
            "validation batch 101 / 107, loss: 33.02\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_9.params\n",
            "global step: 3000, training loss: 21.04, time: 591.50s\n",
            "validation batch 1 / 107, loss: 26.58\n",
            "validation batch 101 / 107, loss: 31.66\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_10.params\n",
            "validation batch 1 / 107, loss: 27.96\n",
            "validation batch 101 / 107, loss: 31.55\n",
            "validation batch 1 / 107, loss: 26.29\n",
            "validation batch 101 / 107, loss: 31.87\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_12.params\n",
            "global step: 4000, training loss: 19.83, time: 783.82s\n",
            "validation batch 1 / 107, loss: 26.36\n",
            "validation batch 101 / 107, loss: 32.32\n",
            "validation batch 1 / 107, loss: 26.54\n",
            "validation batch 101 / 107, loss: 31.24\n",
            "validation batch 1 / 107, loss: 26.03\n",
            "validation batch 101 / 107, loss: 31.20\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_15.params\n",
            "global step: 5000, training loss: 17.71, time: 975.72s\n",
            "validation batch 1 / 107, loss: 26.71\n",
            "validation batch 101 / 107, loss: 32.14\n",
            "validation batch 1 / 107, loss: 25.92\n",
            "validation batch 101 / 107, loss: 31.25\n",
            "validation batch 1 / 107, loss: 26.96\n",
            "validation batch 101 / 107, loss: 32.47\n",
            "global step: 6000, training loss: 18.59, time: 1167.79s\n",
            "validation batch 1 / 107, loss: 25.97\n",
            "validation batch 101 / 107, loss: 30.81\n",
            "validation batch 1 / 107, loss: 25.47\n",
            "validation batch 101 / 107, loss: 30.89\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_20.params\n",
            "validation batch 1 / 107, loss: 25.45\n",
            "validation batch 101 / 107, loss: 30.73\n",
            "global step: 7000, training loss: 18.14, time: 1359.35s\n",
            "validation batch 1 / 107, loss: 25.47\n",
            "validation batch 101 / 107, loss: 30.82\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_22.params\n",
            "validation batch 1 / 107, loss: 25.62\n",
            "validation batch 101 / 107, loss: 30.81\n",
            "validation batch 1 / 107, loss: 25.72\n",
            "validation batch 101 / 107, loss: 30.88\n",
            "validation batch 1 / 107, loss: 25.43\n",
            "validation batch 101 / 107, loss: 31.06\n",
            "global step: 8000, training loss: 15.43, time: 1557.83s\n",
            "validation batch 1 / 107, loss: 25.63\n",
            "validation batch 101 / 107, loss: 31.13\n",
            "validation batch 1 / 107, loss: 25.43\n",
            "validation batch 101 / 107, loss: 30.82\n",
            "validation batch 1 / 107, loss: 25.24\n",
            "validation batch 101 / 107, loss: 30.41\n",
            "save parameters to file: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_28.params\n",
            "global step: 9000, training loss: 19.55, time: 1749.17s\n",
            "validation batch 1 / 107, loss: 25.25\n",
            "validation batch 101 / 107, loss: 30.59\n",
            "validation batch 1 / 107, loss: 25.39\n",
            "validation batch 101 / 107, loss: 30.47\n",
            "validation batch 1 / 107, loss: 25.37\n",
            "validation batch 101 / 107, loss: 30.57\n",
            "global step: 10000, training loss: 19.24, time: 1940.50s\n",
            "validation batch 1 / 107, loss: 25.38\n",
            "validation batch 101 / 107, loss: 30.67\n",
            "validation batch 1 / 107, loss: 25.38\n",
            "validation batch 101 / 107, loss: 30.50\n",
            "validation batch 1 / 107, loss: 25.25\n",
            "validation batch 101 / 107, loss: 30.34\n",
            "global step: 11000, training loss: 19.07, time: 2131.48s\n",
            "validation batch 1 / 107, loss: 25.18\n",
            "validation batch 101 / 107, loss: 30.67\n",
            "validation batch 1 / 107, loss: 25.15\n",
            "validation batch 101 / 107, loss: 30.49\n",
            "validation batch 1 / 107, loss: 25.20\n",
            "validation batch 101 / 107, loss: 30.66\n",
            "global step: 12000, training loss: 16.15, time: 2322.63s\n",
            "validation batch 1 / 107, loss: 25.26\n",
            "validation batch 101 / 107, loss: 30.55\n",
            "validation batch 1 / 107, loss: 25.30\n",
            "validation batch 101 / 107, loss: 30.32\n",
            "validation batch 1 / 107, loss: 25.22\n",
            "validation batch 101 / 107, loss: 30.49\n",
            "global step: 13000, training loss: 17.21, time: 2513.70s\n",
            "validation batch 1 / 107, loss: 25.44\n",
            "validation batch 101 / 107, loss: 30.96\n",
            "validation batch 1 / 107, loss: 25.42\n",
            "validation batch 101 / 107, loss: 30.49\n",
            "validation batch 1 / 107, loss: 25.15\n",
            "validation batch 101 / 107, loss: 30.38\n",
            "global step: 14000, training loss: 17.70, time: 2703.78s\n",
            "validation batch 1 / 107, loss: 25.81\n",
            "validation batch 101 / 107, loss: 31.19\n",
            "validation batch 1 / 107, loss: 25.39\n",
            "validation batch 101 / 107, loss: 30.60\n",
            "validation batch 1 / 107, loss: 25.36\n",
            "validation batch 101 / 107, loss: 30.83\n",
            "validation batch 1 / 107, loss: 25.19\n",
            "validation batch 101 / 107, loss: 30.61\n",
            "global step: 15000, training loss: 19.08, time: 2900.35s\n",
            "validation batch 1 / 107, loss: 25.14\n",
            "validation batch 101 / 107, loss: 30.79\n",
            "validation batch 1 / 107, loss: 25.28\n",
            "validation batch 101 / 107, loss: 30.74\n",
            "validation batch 1 / 107, loss: 25.13\n",
            "validation batch 101 / 107, loss: 30.78\n",
            "global step: 16000, training loss: 17.95, time: 3090.23s\n",
            "validation batch 1 / 107, loss: 25.14\n",
            "validation batch 101 / 107, loss: 30.75\n",
            "validation batch 1 / 107, loss: 25.27\n",
            "validation batch 101 / 107, loss: 30.64\n",
            "validation batch 1 / 107, loss: 25.19\n",
            "validation batch 101 / 107, loss: 30.86\n",
            "global step: 17000, training loss: 17.85, time: 3279.12s\n",
            "validation batch 1 / 107, loss: 25.22\n",
            "validation batch 101 / 107, loss: 30.89\n",
            "validation batch 1 / 107, loss: 25.27\n",
            "validation batch 101 / 107, loss: 30.95\n",
            "validation batch 1 / 107, loss: 25.29\n",
            "validation batch 101 / 107, loss: 31.06\n",
            "global step: 18000, training loss: 18.40, time: 3468.46s\n",
            "validation batch 1 / 107, loss: 25.21\n",
            "validation batch 101 / 107, loss: 31.16\n",
            "validation batch 1 / 107, loss: 25.58\n",
            "validation batch 101 / 107, loss: 31.22\n",
            "validation batch 1 / 107, loss: 25.33\n",
            "validation batch 101 / 107, loss: 31.18\n",
            "global step: 19000, training loss: 17.59, time: 3661.24s\n",
            "validation batch 1 / 107, loss: 25.17\n",
            "validation batch 101 / 107, loss: 31.09\n",
            "validation batch 1 / 107, loss: 25.55\n",
            "validation batch 101 / 107, loss: 31.33\n",
            "validation batch 1 / 107, loss: 25.23\n",
            "validation batch 101 / 107, loss: 31.60\n",
            "global step: 20000, training loss: 18.90, time: 3849.86s\n",
            "validation batch 1 / 107, loss: 25.22\n",
            "validation batch 101 / 107, loss: 31.39\n",
            "validation batch 1 / 107, loss: 25.50\n",
            "validation batch 101 / 107, loss: 31.59\n",
            "validation batch 1 / 107, loss: 25.32\n",
            "validation batch 101 / 107, loss: 31.58\n",
            "global step: 21000, training loss: 17.91, time: 4038.36s\n",
            "validation batch 1 / 107, loss: 25.35\n",
            "validation batch 101 / 107, loss: 31.48\n",
            "validation batch 1 / 107, loss: 25.29\n",
            "validation batch 101 / 107, loss: 31.89\n",
            "validation batch 1 / 107, loss: 25.43\n",
            "validation batch 101 / 107, loss: 31.39\n",
            "global step: 22000, training loss: 19.98, time: 4212.49s\n",
            "validation batch 1 / 107, loss: 25.31\n",
            "validation batch 101 / 107, loss: 32.00\n",
            "validation batch 1 / 107, loss: 25.34\n",
            "validation batch 101 / 107, loss: 31.62\n",
            "validation batch 1 / 107, loss: 25.36\n",
            "validation batch 101 / 107, loss: 31.64\n",
            "validation batch 1 / 107, loss: 25.43\n",
            "validation batch 101 / 107, loss: 31.86\n",
            "global step: 23000, training loss: 16.23, time: 4397.86s\n",
            "validation batch 1 / 107, loss: 25.22\n",
            "validation batch 101 / 107, loss: 31.82\n",
            "validation batch 1 / 107, loss: 25.69\n",
            "validation batch 101 / 107, loss: 32.19\n",
            "validation batch 1 / 107, loss: 25.20\n",
            "validation batch 101 / 107, loss: 31.94\n",
            "global step: 24000, training loss: 17.83, time: 4589.19s\n",
            "validation batch 1 / 107, loss: 25.61\n",
            "validation batch 101 / 107, loss: 32.04\n",
            "validation batch 1 / 107, loss: 26.11\n",
            "validation batch 101 / 107, loss: 32.23\n",
            "validation batch 1 / 107, loss: 25.51\n",
            "validation batch 101 / 107, loss: 32.10\n",
            "global step: 25000, training loss: 16.61, time: 4779.97s\n",
            "validation batch 1 / 107, loss: 25.31\n",
            "validation batch 101 / 107, loss: 32.09\n",
            "best epoch: 28\n",
            "load weight from: experiments/pems04/ASTGCN_h1d0w0_channel1_1.000000e-03/epoch_28.params\n",
            "predicting data set batch 1 / 107\n",
            "predicting data set batch 101 / 107\n",
            "input: (3394, 307, 1, 12)\n",
            "prediction: (3394, 307, 12)\n",
            "data_target_tensor: (3394, 307, 12)\n",
            "current epoch: 28, predict 0 points\n",
            "MAE: 18.08\n",
            "RMSE: 28.85\n",
            "MAPE: 619535208022016.00\n",
            "current epoch: 28, predict 1 points\n",
            "MAE: 18.99\n",
            "RMSE: 30.25\n",
            "MAPE: 722066277924864.00\n",
            "current epoch: 28, predict 2 points\n",
            "MAE: 19.72\n",
            "RMSE: 31.35\n",
            "MAPE: 800769674575872.00\n",
            "current epoch: 28, predict 3 points\n",
            "MAE: 20.28\n",
            "RMSE: 32.22\n",
            "MAPE: 855330590294016.00\n",
            "current epoch: 28, predict 4 points\n",
            "MAE: 20.76\n",
            "RMSE: 32.98\n",
            "MAPE: 907410491310080.00\n",
            "current epoch: 28, predict 5 points\n",
            "MAE: 21.23\n",
            "RMSE: 33.71\n",
            "MAPE: 949024697876480.00\n",
            "current epoch: 28, predict 6 points\n",
            "MAE: 21.76\n",
            "RMSE: 34.53\n",
            "MAPE: 1001879303618560.00\n",
            "current epoch: 28, predict 7 points\n",
            "MAE: 22.31\n",
            "RMSE: 35.37\n",
            "MAPE: 1059443341000704.00\n",
            "current epoch: 28, predict 8 points\n",
            "MAE: 22.90\n",
            "RMSE: 36.28\n",
            "MAPE: 1103929605619712.00\n",
            "current epoch: 28, predict 9 points\n",
            "MAE: 23.57\n",
            "RMSE: 37.25\n",
            "MAPE: 1152128198377472.00\n",
            "current epoch: 28, predict 10 points\n",
            "MAE: 24.36\n",
            "RMSE: 38.38\n",
            "MAPE: 1196734654971904.00\n",
            "current epoch: 28, predict 11 points\n",
            "MAE: 25.28\n",
            "RMSE: 39.67\n",
            "MAPE: 1248154406092800.00\n",
            "all MAE: 21.60\n",
            "all RMSE: 34.38\n",
            "all MAPE: 968035229761536.00\n",
            "[18.078634, 28.849790723758943, 619535200000000.0, 18.993568, 30.252922484408945, 722066300000000.0, 19.720613, 31.347093306861204, 800769700000000.0, 20.27619, 32.2162739258292, 855330600000000.0, 20.763323, 32.978410536644084, 907410500000000.0, 21.229172, 33.709835765600374, 949024700000000.0, 21.76279, 34.534161005693875, 1001879300000000.0, 22.305115, 35.36868973919146, 1059443340000000.0, 22.901493, 36.28388266987923, 1103929600000000.0, 23.571413, 37.254836619726305, 1152128200000000.0, 24.358316, 38.37813473302132, 1196734700000000.0, 25.2752, 39.666306779869075, 1248154400000000.0, 21.602995, 34.383021081223724, 968035200000000.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "params_filename = os.path.join(params_path, 'epoch_%s.params' % 28)\n",
        "net.load_state_dict(torch.load(params_filename, map_location=torch.device('cpu')))\n",
        "predict_and_save_results_mstgcn(net, test_loader, test_target_tensor, 28,_mean, _std, params_path, type)"
      ],
      "metadata": {
        "id": "Q2la8P27-ea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9170ad-a2e0-4343-831d-cf1de9dea38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicting data set batch 1 / 107\n",
            "predicting data set batch 101 / 107\n",
            "input: (3394, 307, 1, 12)\n",
            "prediction: (3394, 307, 12)\n",
            "data_target_tensor: (3394, 307, 12)\n",
            "current epoch: 28, predict 0 points\n",
            "MAE: 18.08\n",
            "RMSE: 28.85\n",
            "MAPE: 619535208022016.00\n",
            "current epoch: 28, predict 1 points\n",
            "MAE: 18.99\n",
            "RMSE: 30.25\n",
            "MAPE: 722066277924864.00\n",
            "current epoch: 28, predict 2 points\n",
            "MAE: 19.72\n",
            "RMSE: 31.35\n",
            "MAPE: 800769674575872.00\n",
            "current epoch: 28, predict 3 points\n",
            "MAE: 20.28\n",
            "RMSE: 32.22\n",
            "MAPE: 855330590294016.00\n",
            "current epoch: 28, predict 4 points\n",
            "MAE: 20.76\n",
            "RMSE: 32.98\n",
            "MAPE: 907410491310080.00\n",
            "current epoch: 28, predict 5 points\n",
            "MAE: 21.23\n",
            "RMSE: 33.71\n",
            "MAPE: 949024697876480.00\n",
            "current epoch: 28, predict 6 points\n",
            "MAE: 21.76\n",
            "RMSE: 34.53\n",
            "MAPE: 1001879303618560.00\n",
            "current epoch: 28, predict 7 points\n",
            "MAE: 22.31\n",
            "RMSE: 35.37\n",
            "MAPE: 1059443341000704.00\n",
            "current epoch: 28, predict 8 points\n",
            "MAE: 22.90\n",
            "RMSE: 36.28\n",
            "MAPE: 1103929605619712.00\n",
            "current epoch: 28, predict 9 points\n",
            "MAE: 23.57\n",
            "RMSE: 37.25\n",
            "MAPE: 1152128198377472.00\n",
            "current epoch: 28, predict 10 points\n",
            "MAE: 24.36\n",
            "RMSE: 38.38\n",
            "MAPE: 1196734654971904.00\n",
            "current epoch: 28, predict 11 points\n",
            "MAE: 25.28\n",
            "RMSE: 39.67\n",
            "MAPE: 1248154406092800.00\n",
            "all MAE: 21.60\n",
            "all RMSE: 34.38\n",
            "all MAPE: 968035229761536.00\n",
            "[18.078634, 28.849790723758943, 619535200000000.0, 18.993568, 30.252922484408945, 722066300000000.0, 19.720613, 31.347093306861204, 800769700000000.0, 20.27619, 32.2162739258292, 855330600000000.0, 20.763323, 32.978410536644084, 907410500000000.0, 21.229172, 33.709835765600374, 949024700000000.0, 21.76279, 34.534161005693875, 1001879300000000.0, 22.305115, 35.36868973919146, 1059443340000000.0, 22.901493, 36.28388266987923, 1103929600000000.0, 23.571413, 37.254836619726305, 1152128200000000.0, 24.358316, 38.37813473302132, 1196734700000000.0, 25.2752, 39.666306779869075, 1248154400000000.0, 21.602995, 34.383021081223724, 968035200000000.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.train(False)  # ensure dropout layers are in test mode\n",
        "all_labels = torch.tensor([])\n",
        "all_outputs = torch.tensor([])\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    data_target_tensor = test_target_tensor.cpu().numpy()\n",
        "\n",
        "    loader_length = len(test_loader)  # nb of batch\n",
        "\n",
        "    prediction = []  \n",
        "\n",
        "    input = []  \n",
        "\n",
        "    for batch_index, batch_data in enumerate(test_loader):\n",
        "\n",
        "        encoder_inputs, labels = batch_data\n",
        "\n",
        "        input.append(encoder_inputs[:, :, 0:1].cpu().numpy())  # (batch, T', 1)\n",
        "\n",
        "        outputs = net(encoder_inputs)\n",
        "\n",
        "        all_labels = torch.cat([all_labels, labels.cpu()])\n",
        "        all_outputs = torch.cat([all_outputs, outputs.cpu()])"
      ],
      "metadata": {
        "id": "PeYxCUffoWzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output = all_outputs[0]  # prediction\n",
        "sample_labels = all_labels[0] # truth\n",
        "print(sample_output.shape, sample_labels.shape)"
      ],
      "metadata": {
        "id": "Ratwh5aqqvnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1fb035-ef5a-4c67-bea3-f304753b6eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([307, 12]) torch.Size([307, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(30,4), dpi=80)\n",
        "for i in range(50):\n",
        "    new_i = i * 12\n",
        "    plt.plot(range(0+new_i,12+new_i),sample_output[i], color = 'red')\n",
        "    plt.plot(range(0+new_i,12+new_i),sample_labels[i], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sitsvSnsq0tg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "91ff968a-d603-4eb6-d84e-29ed79e6e9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x320 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}